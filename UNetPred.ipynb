{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4dbfa4-f712-4bf3-9f62-8cf306b34b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as tf\n",
    "from torch.optim import adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "import hyperspy.api as hs\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device type: %s\"%(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a259d3d1-8cef-4092-bbaa-e1732194c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    images = np.load(...)\n",
    "    masks = np.load(...)\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "def load_signal(lazy = True):\n",
    "    return hs.load(..., lazy = lazy)\n",
    "\n",
    "def to_tensor(image):\n",
    "    image = np.abs(image)\n",
    "    image = np.where(image != 0, np.log2(image), 0)\n",
    "    image =  2*(image / np.max(image)) - 1 # normalize: -1 to 1\n",
    "\n",
    "    if len(image.shape) == 2:\n",
    "        return torch.tensor(np.expand_dims(image, axis=0), dtype = torch.float32).unsqueeze(0).to(device)\n",
    "    return [[torch.tensor(np.expand_dims(element, axis=0), dtype = torch.float32).unsqueeze(0).to(device) for element in row] for row in image]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd052fbe-2455-403b-8499-404fdeb1def4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-4\n",
    "depth = 3\n",
    "filters = 5\n",
    "base_path = ...\n",
    "out_path = ...\n",
    "filename = f'\\segmentation_lr{learning_rate}_depth{depth}_filters{filters}_combo_'\n",
    "PATH = out_path + filename + \"model.pth\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model = UNet(in_channels = 1, n_classes = 2, depth = depth, wf = filters, padding = True)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "print('Model Loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8d4b03-d4bb-433b-a8b4-2b3d0eef0d94",
   "metadata": {},
   "source": [
    "## The following cells are for predicting simulated diffraction patters, or a few selected diffraction patters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff981ae-7cec-4425-9708-9ddee7049d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647661e-d1ec-425c-b079-aae9bb10bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "for i in range(len(images)):\n",
    "    image = images[i]\n",
    "    im = to_tensor(image)\n",
    "    with torch.no_grad():\n",
    "        pred = model(im)\n",
    "        output = torch.argmax(pred, dim=1)  # Get the index of the channel with the highest probability\n",
    "        output = output.squeeze(0).cpu().numpy()\n",
    "        prediction.append(output)\n",
    "    im = im[0].detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845fcbc-e8cc-4d9a-b1cd-8b807c416544",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(images)):\n",
    "   plt.figure()\n",
    "   plt.imshow(images[i], norm = \"symlog\")\n",
    "   plt.figure()\n",
    "   plt.imshow(prediction[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7d4927-0b9f-45fb-b367-2c03784243d2",
   "metadata": {},
   "source": [
    "## Predicting an entire signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b97666-dbe4-4fde-8cbf-b9c654181053",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = hs.load(..., lazy=False)\n",
    "#If RAM is a concern, it may be necessary to crop the signal.\n",
    "#signal = signal.inav[:128,:128]\n",
    "data = signal.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497014f-ac94-436b-a0bd-e9ea9752a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = to_tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481d578c-baa0-4c55-899a-710d80f648af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(x, y, img):\n",
    "    with torch.no_grad():\n",
    "        pred = model(img)\n",
    "        output = torch.argmax(pred, dim=1)  # Get the index of the channel with the highest probability\n",
    "        return x, y, output.squeeze(0).cpu().numpy()\n",
    "\n",
    "prediction = np.zeros(data.shape)\n",
    "\n",
    "\n",
    "# Generate list of tuples with arguments for the process_image function\n",
    "image_args = [(x, y, img) for x, row in enumerate(images[:10]) for y, img in enumerate(row)]\n",
    "\n",
    "with Parallel(n_jobs=-1) as parallel:\n",
    "    results = list(tqdm(parallel(delayed(process_image)(*args) for args in image_args), total=len(image_args)))\n",
    "\n",
    "for x, y, result in results:\n",
    "    prediction[x, y] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f7868a-3d9d-4943-a889-5ce9b3140dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.data = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a811937-d927-4b76-b95b-73fe68663476",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f13f0e3-606f-46d9-80c3-686d0bc952b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.save(...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
